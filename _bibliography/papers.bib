@Article{deSouza2020,
author={de Souza, Adriano Fagali
and Martins, Juliana
and Maiochi, Henrique
and Juliani, Aline Durrer Patelli
and Jaskowiak, Pablo Andretta},
title={Development of a mobile application for monitoring and controlling a CNC machine using Industry 4.0 concepts},
journal={The International Journal of Advanced Manufacturing Technology},
year={2020},
month={Dec},
day={01},
volume={111},
number={9},
pages={2545-2552},
abstract={Industry 4.0 comprises a set of technologies that allow the interconnection, monitoring, and controlling of manufacturing processes. Today it represents a key point for the modern industry. The current work presents an Industry 4.0 system developed for monitoring and controlling a 5-axis CNC machine center, in real time, through a mobile device, providing important feedback information for users and manufacturers of the machine. Given that response time is crucial in such applications, we conducted an experimental investigation to examine the system latency with distinct database structures, based on SQL and NoSQL. The results suggest that the non-relational structure (NoSQL) presented lower response times and is, thus, best suited for the application in hand. The system allows monitoring and controlling of any CNC machine remotely---given that a middleware for connecting the machine is provided---in real time, presenting new possibilities from the perspectives of machine tool builders and shop floor management.},
issn={1433-3015},
doi={10.1007/s00170-020-06245-2},
url={https://doi.org/10.1007/s00170-020-06245-2}
}



@InProceedings{10.1007/978-3-642-31927-3_11,
author="Jaskowiak, Pablo A.
and Campello, Ricardo J. G. B.
and Costa, Ivan G.",
editor="de Souto, Marcilio C.
and Kann, Maricel G.",
title="Evaluating Correlation Coefficients for Clustering Gene Expression Profiles of Cancer",
booktitle="Advances in Bioinformatics and Computational Biology",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="120--131",
abstract="Cluster analysis is usually the first step adopted to unveil information from gene expression data. One of its common applications is the clustering of cancer samples, associated with the detection of previously unknown cancer subtypes. Although guidelines have been established concerning the choice of appropriate clustering algorithms, little attention has been given to the subject of proximity measures. Whereas the Pearson correlation coefficient appears as the de facto proximity measure in this scenario, no comprehensive study analyzing other correlation coefficients as alternatives to it has been conducted. Considering such facts, we evaluated five correlation coefficients (along with Euclidean distance) regarding the clustering of cancer samples. Our evaluation was conducted on 35 publicly available datasets covering both (i) intrinsic separation ability and (ii) clustering predictive ability of the correlation coefficients. Our results support that correlation coefficients rarely considered in the gene expression literature may provide competitive results to more generally employed ones. Finally, we show that a recently introduced measure arises as a promising alternative to the commonly employed Pearson, providing competitive and even superior results to it.",
isbn="978-3-642-31927-3"
}


@article{BARROS20143,
title = {A framework for bottom-up induction of oblique decision trees},
journal = {Neurocomputing},
volume = {135},
pages = {3-12},
year = {2014},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2013.01.067},
url = {https://www.sciencedirect.com/science/article/pii/S0925231213011351},
author = {Rodrigo C. Barros and Pablo A. Jaskowiak and Ricardo Cerri and Andre C.P.L.F. {de Carvalho}},
keywords = {Oblique decision trees, Bottom-up induction, Clustering},
abstract = {Decision-tree induction algorithms are widely used in knowledge discovery and data mining, specially in scenarios where model comprehensibility is desired. A variation of the traditional univariate approach is the so-called oblique decision tree, which allows multivariate tests in its non-terminal nodes. Oblique decision trees can model decision boundaries that are oblique to the attribute axes, whereas univariate trees can only perform axis-parallel splits. The vast majority of the oblique and univariate decision-tree induction algorithms employ a top-down strategy for growing the tree, relying on an impurity-based measure for splitting nodes. In this paper, we propose BUTIF—a novel Bottom-Up Oblique Decision-Tree Induction Framework. BUTIF does not rely on an impurity-measure for dividing nodes, since the data resulting from each split is known a priori. For generating the initial leaves of the tree and the splitting hyperplanes in its internal nodes, BUTIF allows the adoption of distinct clustering algorithms and binary classifiers, respectively. It is also capable of performing embedded feature selection, which may reduce the number of features in each hyperplane, thus improving model comprehension. Different from virtually every top-down decision-tree induction algorithm, BUTIF does not require the further execution of a pruning procedure in order to avoid overfitting, due to its bottom-up nature that does not overgrow the tree. We compare distinct instances of BUTIF to traditional univariate and oblique decision-tree induction algorithms. Empirical results show the effectiveness of the proposed framework.}
}

﻿@Article{Jaskowiak2016,
author={Jaskowiak, Pablo A.
and Moulavi, Davoud
and Furtado, Antonio C. S.
and Campello, Ricardo J. G. B.
and Zimek, Arthur
and Sander, J{\"o}rg},
title={On strategies for building effective ensembles of relative clustering validity criteria},
journal={Knowledge and Information Systems},
year={2016},
month={May},
day={01},
volume={47},
number={2},
pages={329-354},
abstract={Evaluation and validation are essential tasks for achieving meaningful clustering results. Relative validity criteria are measures usually employed in practice to select and validate clustering solutions, as they enable the evaluation of single partitions and the comparison of partition pairs in relative terms based only on the data under analysis. There is a plethora of relative validity measures described in the clustering literature, thus making it difficult to choose an appropriate measure for a given application. One reason for such a variety is that no single measure can capture all different aspects of the clustering problem and, as such, each of them is prone to fail in particular application scenarios. In the present work, we take advantage of the diversity in relative validity measures from the clustering literature. Previous work showed that when randomly selecting different relative validity criteria for an ensemble (from an initial set of 28 different measures), one can expect with great certainty to only improve results over the worst criterion included in the ensemble. In this paper, we propose a method for selecting measures with minimum effectiveness and some degree of complementarity (from the same set of 28 measures) into ensembles, which show superior performance when compared to any single ensemble member (and not just the worst one) over a variety of different datasets. One can also expect greater stability in terms of evaluation over different datasets, even when considering different ensemble strategies. Our results are based on more than a thousand datasets, synthetic and real, from different sources.},
issn={0219-3116},
doi={10.1007/s10115-015-0851-6},
url={https://doi.org/10.1007/s10115-015-0851-6}
}



@INPROCEEDINGS{6121697,
  author={Barros, Rodrigo C. and Cerri, Ricardo and Jaskowiak, Pablo A. and de Carvalho, Andr\'{e} C. P. L. F.},
  booktitle={2011 11th International Conference on Intelligent Systems Design and Applications}, 
  title={A bottom-up oblique decision tree induction algorithm}, 
  year={2011},
  volume={},
  number={},
  pages={450-456},
  doi={10.1109/ISDA.2011.6121697},
  abstract = {Decision tree induction algorithms are widely used in knowledge discovery and data mining, specially in scenarios where model comprehensibility is desired. A variation of the traditional univariate approach is the so-called oblique decision tree, which allows multivariate tests in its non-terminal nodes. Oblique decision trees can model decision boundaries that are oblique to the attribute axes, whereas univariate trees can only perform axis-parallel splits. The majority of the oblique and univariate decision tree induction algorithms perform a top-down strategy for growing the tree, relying on an impurity-based measure for splitting nodes. In this paper, we propose a novel bottom-up algorithm for inducing oblique trees named BUTIA. It does not require an impurity-measure for dividing nodes, since we know a priori the data resulting from each split. For generating the splitting hyperplanes, our algorithm implements a support vector machine solution, and a clustering algorithm is used for generating the initial leaves. We compare BUTIA to traditional univariate and oblique decision tree algorithms, C4.5, CART, OC1 and FT, as well as to a standard SVM implementation, using real gene expression benchmark data. Experimental results show the effectiveness of the proposed approach in several cases.}
  }


﻿@Article{deSouto2015,
author={de Souto, Marcilio CP
and Jaskowiak, Pablo A.
and Costa, Ivan G.},
title={Impact of missing data imputation methods on gene expression clustering and classification},
journal={BMC Bioinformatics},
year={2015},
month={Feb},
day={26},
volume={16},
number={1},
pages={64},
abstract={Several missing value imputation methods for gene expression data have been proposed in the literature. In the past few years, researchers have been putting a great deal of effort into presenting systematic evaluations of the different imputation algorithms. Initially, most algorithms were assessed with an emphasis on the accuracy of the imputation, using metrics such as the root mean squared error. However, it has become clear that the success of the estimation of the expression value should be evaluated in more practical terms as well. One can consider, for example, the ability of the method to preserve the significant genes in the dataset, or its discriminative/predictive power for classification/clustering purposes.},
issn={1471-2105},
doi={10.1186/s12859-015-0494-3},
url={https://doi.org/10.1186/s12859-015-0494-3}
}

@article{JasCamCos14,
author = {Jaskowiak, Pablo A. and Campello, Ricardo J. G. B. and Costa, Ivan G.},
doi = {10.1186/1471-2105-15-S2-S2},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Cluster Analysis,Gene Expression Profiling,Gene Expression Profiling: methods,Humans,Neoplasms,Neoplasms: genetics,Oligonucleotide Array Sequence Analysis,Oligonucleotide Array Sequence Analysis: methods},
month = jan,
number = {Suppl 2},
pages = {S2},
pmid = {24564555},
title = {{On the selection of appropriate distances for gene expression data clustering.}},
url = {http://www.biomedcentral.com/1471-2105/15/S2/S2},
volume = {15 Suppl 2},
year = {2014},
abstract = {Background: Clustering is crucial for gene expression data analysis. As an unsupervised exploratory procedure its results can help researchers to gain insights and formulate new hypothesis about biological data from microarrays. Given different settings of microarray experiments, clustering proves itself as a versatile exploratory tool. It can help to unveil new cancer subtypes or to identify groups of genes that respond similarly to a specific experimental condition. In order to obtain useful clustering results, however, different parameters of the clustering procedure must be properly tuned. Besides the selection of the clustering method itself, determining which distance is going to be employed between data objects is probably one of the most difficult decisions. Results and conclusions: We analyze how different distances and clustering methods interact regarding their ability to cluster gene expression, i.e., microarray data. We study 15 distances along with four common clustering methods from the literature on a total of 52 gene expression microarray datasets. Distances are evaluated on a number of different scenarios including clustering of cancer tissues and genes from short time-series expression data, the two main clustering applications in gene expression. Our results support that the selection of an appropriate distance depends on the scenario in hand. Moreover, in each scenario, given the very same clustering method, significant differences in quality may arise from the selection of distinct distance measures. In fact, the selection of an appropriate distance measure can make the difference between meaningful and poor clustering outcomes, even for a suitable clustering method.}
}

@inbook{Moulavi,
author = {Davoud Moulavi and Pablo A. Jaskowiak and Ricardo J. G. B. Campello and Arthur Zimek and J\"{o}rg Sander},
title = {Density-Based Clustering Validation},
booktitle = {Proceedings of the 2014 SIAM International Conference on Data Mining (SDM)},
chapter = {},
year = {2013},
pages = {839-847},
doi = {10.1137/1.9781611973440.96},
    abstract = { Abstract One of the most challenging aspects of clustering is validation, which is the objective and quantitative assessment of clustering results. A number of different relative validity criteria have been proposed for the validation of globular, clusters. Not all data, however, are composed of globular clusters. Density-based clustering algorithms seek partitions with high density areas of points (clusters, not necessarily globular) separated by low density areas, possibly containing noise objects. In these cases relative validity indices proposed for globular cluster validation may fail. In this paper we propose a relative validation index for density-based, arbitrarily shaped clusters. The index assesses clustering quality based on the relative density connection between pairs of objects. Our index is formulated on the basis of a new kernel density function, which is used to compute the density of objects and to evaluate the within- and between-cluster density connectedness of clustering results. Experiments on synthetic and real world data show the effectiveness of our approach for the evaluation and selection of clustering algorithms and their respective appropriate parameters. }
}

@article{JasCamCos13,
 author = {Jaskowiak, Pablo A. and Campello, Ricardo J.  G.  B. and Costa, Ivan G.},
 title = {Proximity Measures for Clustering Gene Expression Microarray Data: A Validation Methodology and a Comparative Analysis},
 journal = {IEEE TCBB},
 issue_date = {July 2013},
 volume = {10},
 number = {4},
 year = {2013},
 issn = {1545-5963},
 pages = {845--857},
 numpages = {13},
 url = {http://dx.doi.org/10.1109/TCBB.2013.9},
 doi = {10.1109/TCBB.2013.9},
 acmid = {2564679},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {Proximity measure, distance, similarity, correlation coefficient, clustering, gene expression, cancer, time course},
 abstract = {Cluster analysis is usually the first step adopted to unveil information from gene expression microarray data. Besides selecting a clustering algorithm, choosing an appropriate proximity measure (similarity or distance) is of great importance to achieve satisfactory clustering results. Nevertheless, up to date, there are no comprehensive guidelines concerning how to choose proximity measures for clustering microarray data. Pearson is the most used proximity measure, whereas characteristics of other ones remain unexplored. In this paper, we investigate the choice of proximity measures for the clustering of microarray data by evaluating the performance of 16 proximity measures in 52 data sets from time course and cancer experiments. Our results support that measures rarely employed in the gene expression literature can provide better results than commonly employed ones, such as Pearson, Spearman, and euclidean distance. Given that different measures stood out for time course and cancer data evaluations, their choice should be specific to each scenario. To evaluate measures on time-course data, we preprocessed and compiled 17 data sets from the microarray literature in a benchmark along with a new methodology, called Intrinsic Biological Separation Ability (IBSA). Both can be employed in future research to assess the effectiveness of new measures for gene time-course data.}
} 
